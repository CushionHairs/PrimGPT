{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def get_articles(query):\n",
    "    api_key = os.getenv('SERPAPI_KEY')\n",
    "    url = f\"https://serpapi.com/search.json?q={query}&api_key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def find_best_articles(search_results):\n",
    "    prompt = \"Given the following search results, select the best three articles and return their URLs:\\n\" + str(search_results)\n",
    "    response = OpenAI.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(article_content):\n",
    "    prompt = \"Summarize the following article:\\n\" + article_content\n",
    "    response = OpenAI.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_twitter_thread(summaries):\n",
    "    prompt = \"Create a viral Twitter thread based on the following summaries:\\n\" + \"\\n\".join(summaries)\n",
    "    response = OpenAI.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=280\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"Autonomous Researcher\")\n",
    "topic = st.text_input(\"Enter a topic for Twitter thread:\")\n",
    "if st.button(\"Generate\"):\n",
    "    articles = get_articles(topic)\n",
    "    best_articles = find_best_articles(articles)\n",
    "    summaries = [summarize_article(article) for article in best_articles]\n",
    "    twitter_thread = generate_twitter_thread(summaries)\n",
    "    st.write(twitter_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bing ì„ í†µí•œ ì›¹ê²€ìƒ‰ ê²°ê³¼ì™€ í•¨ê»˜ OpenAI API ë¥¼ ì‚¬ìš©í•˜ëŠ” ì½”ë“œ\n",
    "import requests\n",
    "import openai\n",
    "\n",
    "# API í‚¤ ì„¤ì •\n",
    "openai.api_key = \"ë‹¹ì‹ ì˜_OpenAI_API_í‚¤\"\n",
    "bing_api_key = \"ë‹¹ì‹ ì˜_Bing_API_í‚¤\"\n",
    "\n",
    "# Bing Web Search APIë¥¼ í™œìš©í•œ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜\n",
    "def bing_search(query):\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": bing_api_key}\n",
    "    params = {\"q\": query, \"textDecorations\": True, \"textFormat\": \"HTML\", \"count\": 3}\n",
    "    search_url = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "    response = requests.get(search_url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "\n",
    "    snippets = []\n",
    "    for result in search_results[\"webPages\"][\"value\"]:\n",
    "        snippets.append(f\"{result['name']}: {result['snippet']}\")\n",
    "    return \"\\n\".join(snippets)\n",
    "\n",
    "# ê²€ìƒ‰ ì§ˆë¬¸ ì…ë ¥\n",
    "user_question = \"ìµœê·¼ í•œêµ­ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ìŠ¤ë§ˆíŠ¸í° ëª¨ë¸ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "# Bing APIë¥¼ í†µí•´ ìµœì‹  ì •ë³´ ê²€ìƒ‰\n",
    "search_results = bing_search(user_question)\n",
    "\n",
    "# GPT ëª¨ë¸ì—ê²Œ ê²€ìƒ‰ ê²°ê³¼ì™€ ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±\n",
    "prompt = f\"\"\"\n",
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì…ë‹ˆë‹¤: \"{user_question}\"\n",
    "\n",
    "ì•„ë˜ëŠ” Bing ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì–»ì€ ìµœì‹  ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n",
    "{search_results}\n",
    "\n",
    "ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# OpenAI APIë¡œ ë‹µë³€ ìƒì„±\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(\"ğŸŒ¸âœ¨ ë‹µë³€:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea35f5a6d00afa1252be7cd25285aca3440ede00562df77e2fe926b15eee10d0\n"
     ]
    }
   ],
   "source": [
    "import secrets \n",
    "\n",
    "token_key = secrets.token_hex(32)\n",
    "print(token_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt4o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
